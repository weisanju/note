## Ingest processor reference

https://www.elastic.co/guide/en/elasticsearch/reference/7.17/processors.html



Elasticsearch includes several configurable processors. To get a list of available processors, use the [nodes info](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/cluster-nodes-info.html) API.

```console
GET _nodes/ingest?filter_path=nodes.*.ingest.processors
```

### Processor plugins

You can install additional processors as [plugins](https://www.elastic.co/guide/en/elasticsearch/plugins/7.17/ingest.html).

您必须在集群中的所有节点上安装任何插件处理器。否则，Elasticsearch将无法创建包含处理器的管道。

通过在elasticsearch.yml中设置plugin，将插件标记为必填项。如果未安装强制插件，则节点将无法启动。





```yaml
plugin.mandatory: ingest-attachment
```



## Append processor

Appends one or more values to an existing array if the field already exists and it is an array. Converts a scalar to an array and appends one or more values to it if the field exists and it is a scalar. Creates an array containing the provided values if the field doesn’t exist. Accepts a single value or an array of values.

如果字段已经存在并且是数组，则将一个或多个值附加到现有数组。将标量转换为数组，如果字段存在并且是标量，则将一个或多个值附加到数组。如果字段不存在，则创建一个包含提供的值的数组。接受单个值或值数组。



**Table 3. Append Options**

| Name               | Required | Default            | Description                                                  |
| ------------------ | -------- | ------------------ | ------------------------------------------------------------ |
| `field`            | yes      | -                  | The field to be appended to. Supports [template snippets](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#template-snippets). |
| `value`            | yes      | -                  | The value to be appended. Supports [template snippets](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#template-snippets). |
| `allow_duplicates` | no       | true               | If `false`, the processor does not append values already present in the field. |
| `media_type`       | no       | `application/json` | The media type for encoding `value`. Applies only when `value` is a [template snippet](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#template-snippets). Must be one of `application/json`, `text/plain`, or `application/x-www-form-urlencoded`. |
| `description`      | no       | -                  | Description of the processor. Useful for describing the purpose of the processor or its configuration. |
| `if`               | no       | -                  | Conditionally execute the processor. See [Conditionally run a processor](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#conditionally-run-processor). |
| `ignore_failure`   | no       | `false`            | Ignore failures for the processor. See [Handling pipeline failures](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#handling-pipeline-failures). |
| `on_failure`       | no       | -                  | Handle failures for the processor. See [Handling pipeline failures](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#handling-pipeline-failures). |
| `tag`              | no       | -                  | Identifier for the processor. Useful for debugging and metrics. |

```js
{
  "append": {
    "field": "tags",
    "value": ["production", "{{{app}}}", "{{{owner}}}"]
  }
}
```

## Bytes processor

将人类可读字节值 (例如1kb) 转换为其以字节为单位的值 (例如1024)。如果该字段是字符串数组，则该数组的所有成员都将被转换。

支持的人类可读单位是 “b”，“kb”，“mb”，“gb”，“tb”，“pb” 大小写不敏感。如果该字段不是受支持的格式或结果值超过2 ^ 63，则会发生错误。

| Name             | Required | Default | Description                                                  |
| ---------------- | -------- | ------- | ------------------------------------------------------------ |
| `field`          | yes      | -       | The field to convert                                         |
| `target_field`   | no       | `field` | The field to assign the converted value to, by default `field` is updated in-place |
| `ignore_missing` | no       | `false` | If `true` and `field` does not exist or is `null`, the processor quietly exits without modifying the document |
| `description`    | no       | -       | Description of the processor. Useful for describing the purpose of the processor or its configuration. |
| `if`             | no       | -       | Conditionally execute the processor. See [Conditionally run a processor](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#conditionally-run-processor). |
| `ignore_failure` | no       | `false` | Ignore failures for the processor. See [Handling pipeline failures](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#handling-pipeline-failures). |
| `on_failure`     | no       | -       | Handle failures for the processor. See [Handling pipeline failures](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#handling-pipeline-failures). |
| `tag`            | no       | -       | Identifier for the processor. Useful for debugging and metrics. |

## Circle processor

Converts circle definitions of shapes to regular polygons which approximate them.

[详见](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest-circle-processor.html)

## CSV processor

从文档中的单个文本字段中提取CSV行中的字段。CSV中的任何空字段都将被跳过。

| Name             | Required | Default | Description                                                  |
| ---------------- | -------- | ------- | ------------------------------------------------------------ |
| `field`          | yes      | -       | The field to extract data from                               |
| `target_fields`  | yes      | -       | The array of fields to assign extracted values to            |
| `separator`      | no       | ,       | Separator used in CSV, has to be single character string     |
| `quote`          | no       | "       | Quote used in CSV, has to be single character string         |
| `ignore_missing` | no       | `true`  | If `true` and `field` does not exist, the processor quietly exits without modifying the document |
| `trim`           | no       | `false` | Trim whitespaces in unquoted fields                          |
| `empty_value`    | no       | -       | Value used to fill empty fields, empty fields will be skipped if this is not provided. Empty field is one with no value (2 consecutive separators) or empty quotes (`""`) |
| `description`    | no       | -       | Description of the processor. Useful for describing the purpose of the processor or its configuration. |
| `if`             | no       | -       | Conditionally execute the processor. See [Conditionally run a processor](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#conditionally-run-processor). |
| `ignore_failure` | no       | `false` | Ignore failures for the processor. See [Handling pipeline failures](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#handling-pipeline-failures). |
| `on_failure`     | no       | -       | Handle failures for the processor. See [Handling pipeline failures](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#handling-pipeline-failures). |
| `tag`            | no       | -       | Identifier for the processor. Useful for debugging and metrics. |





## Grok processor

从文档中的单个文本字段中提取结构化字段。您可以选择从中提取匹配字段的字段，以及您期望匹配的grok模式。

grok模式就像一个正则表达式，它支持可以重复使用的别名表达式。

该处理器包装有许多可重复使用的 [pattern](https://github.com/elastic/elasticsearch/blob/7.17/libs/grok/src/main/resources/patterns) 

If you need help building patterns to match your logs, 

如果您需要帮助构建模式来匹配您的日志

you will find the [Grok Debugger](https://www.elastic.co/guide/en/kibana/7.17/xpack-grokdebugger.html) tool quite useful! The [Grok Constructor](https://grokconstructor.appspot.com/) is also a useful tool.

### Using the Grok Processor in a Pipeline

**Table 21. Grok Options**

| Name                  | Required | Default    | Description                                                  |
| --------------------- | -------- | ---------- | ------------------------------------------------------------ |
| `field`               | yes      | -          | The field to use for grok expression parsing                 |
| `patterns`            | yes      | -          | An ordered list of grok expression to match and extract named captures with. Returns on the first expression in the list that matches. |
| `pattern_definitions` | no       | -          | A map of pattern-name and pattern tuples defining custom patterns to be used by the current processor. Patterns matching existing names will override the pre-existing definition. |
| `ecs_compatibility`   | no       | `disabled` | Must be `disabled` or `v1`. If `v1`, the processor uses patterns with [Elastic Common Schema (ECS)](https://www.elastic.co/guide/en/ecs/1.12/ecs-field-reference.html) field names. |
| `trace_match`         | no       | false      | when true, `_ingest._grok_match_index` will be inserted into your matched document’s metadata with the index into the pattern found in `patterns` that matched. |
| `ignore_missing`      | no       | false      | If `true` and `field` does not exist or is `null`, the processor quietly exits without modifying the document |
| `description`         | no       | -          | Description of the processor. Useful for describing the purpose of the processor or its configuration. |
| `if`                  | no       | -          | Conditionally execute the processor. See [Conditionally run a processor](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#conditionally-run-processor). |
| `ignore_failure`      | no       | `false`    | Ignore failures for the processor. See [Handling pipeline failures](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#handling-pipeline-failures). |
| `on_failure`          | no       | -          | Handle failures for the processor. See [Handling pipeline failures](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/ingest.html#handling-pipeline-failures). |
| `tag`                 | no       | -          | Identifier for the processor. Useful for debugging and metrics. |





### Custom Patterns

The Grok processor comes pre-packaged with a base set of patterns. These patterns may not always have what you are looking for. Patterns have a very basic format. Each entry has a name and the pattern itself.

Grok处理器预先包装了一组基本模式。这些模式可能并不总是有你想要的。模式有一个非常基本的格式。每个条目都有一个名称和*pattern*。



您可以在*pattern_definitions*选项下将自己的模式添加到处理器定义中。下面是指定自定义模式定义的管道示例:

```js
{
  "description" : "...",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["my %{FAVORITE_DOG:dog} is colored %{RGB:color}"],
        "pattern_definitions" : {
          "FAVORITE_DOG" : "beagle",
          "RGB" : "RED|GREEN|BLUE"
        }
      }
    }
  ]
}
```





### Providing Multiple Match Patterns

有时，一种模式不足以捕获子段的潜在结构。假设我们要匹配所有包含您最喜欢的猫或狗的宠物品种的消息。实现此目的的一种方法是提供可以匹配的两种不同模式，而不是一种捕获相同或行为的真正复杂的表达。

Here is an example of such a configuration executed against the simulate API:

```console
POST _ingest/pipeline/_simulate
{
  "pipeline": {
  "description" : "parse multiple patterns",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["%{FAVORITE_DOG:pet}", "%{FAVORITE_CAT:pet}"],
        "pattern_definitions" : {
          "FAVORITE_DOG" : "beagle",
          "FAVORITE_CAT" : "burmese"
        }
      }
    }
  ]
},
"docs":[
  {
    "_source": {
      "message": "I love burmese cats!"
    }
  }
  ]
}
```



两种模式都将为字段设置适当的匹配项，但是如果我们想跟踪哪个模式匹配并填充了我们的字段，该怎么办

We can do this with the `trace_match` parameter. Here is the output of that same pipeline, but with `"trace_match": true` configured:

我们可以使用trace_match参数来执行此操作。这里是同一管道的输出，但与 *“trace_match”: true*配置:

```console-result
{
  "docs": [
    {
      "doc": {
        "_type": "_doc",
        "_index": "_index",
        "_id": "_id",
        "_source": {
          "message": "I love burmese cats!",
          "pet": "burmese"
        },
        "_ingest": {
          "_grok_match_index": "1",
          "timestamp": "2016-11-08T19:43:03.850+0000"
        }
      }
    }
  ]
}
```

In the above response, you can see that the index of the pattern that matched was `"1"`.

 This is to say that it was the second (index starts at zero) pattern in `patterns` to match.

这个跟踪元数据可以调试匹配的模式。此信息存储在ingest metadata  中，不会被索引。

### Retrieving patterns from REST endpoint

The Grok processor comes packaged with its own REST endpoint for retrieving the patterns included with the processor.

*Grok processor* 随附了自己的REST端点，用于检索 处理器预定义的模式。

```console
GET _ingest/processor/grok
```

The above request will return a response body containing a key-value representation of the built-in patterns dictionary.

```js
{
  "patterns" : {
    "BACULA_CAPACITY" : "%{INT}{1,3}(,%{INT}{3})*",
    "PATH" : "(?:%{UNIXPATH}|%{WINPATH})",
    ...
}
```

By default, the API returns a list of legacy Grok patterns.

 These legacy patterns predate the [Elastic Common Schema (ECS)](https://www.elastic.co/guide/en/ecs/1.12/ecs-field-reference.html) and don’t use ECS field names. To return patterns that extract ECS field names, specify `v1` in the optional `ecs_compatibility` query parameter.

```console
GET _ingest/processor/grok?ecs_compatibility=v1
```

By default, the API returns patterns in the order they are read from disk.

默认情况下，API按照从磁盘读取的顺序返回模式。这种排序顺序保留了相关模式的分组。例如，与解析Linux syslog行相关的所有模式都保存在一起。

您可以使用可选的boolean s查询参数来按键名对返回的模式进行排序。

```console
GET _ingest/processor/grok?s
```

The API returns the following response.

```js
{
  "patterns" : {
    "BACULA_CAPACITY" : "%{INT}{1,3}(,%{INT}{3})*",
    "BACULA_DEVICE" : "%{USER}",
    "BACULA_DEVICEPATH" : "%{UNIXPATH}",
    ...
}
```

This can be useful to reference as the built-in patterns change across versions.

### Grok watchdog



执行时间太长的Grok表达式被中断，然后grok处理器出现异常失败。

grok处理器有一个看门狗线程，该线程确定grok表达式的求值时间过长，并由以下设置控制:



| Name                                      | Default | Description                                                  |
| ----------------------------------------- | ------- | ------------------------------------------------------------ |
| `ingest.grok.watchdog.interval`           | 1s      | How often to check whether there are grok evaluations that take longer than the maximum allowed execution time. |
| `ingest.grok.watchdog.max_execution_time` | 1s      | The maximum allowed execution of a grok expression evaluation. |

### Grok debugging

建议使用 [Grok Debugger](https://www.elastic.co/guide/en/kibana/7.17/xpack-grokdebugger.html) 来调试grok模式。从那里，您可以针对示例数据测试UI中的一个或多个模式，它使用与摄取节点处理器相同的引擎。

Additionally, it is recommended to enable debug logging for Grok so that any additional messages may also be seen in the Elasticsearch server log.

此外，建议为Grok启用调试日志记录，以便在Elasticsearch服务器日志中也可以看到任何其他消息。