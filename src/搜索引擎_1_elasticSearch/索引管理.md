

## 创建索引

```js
PUT /my_index
{
    "settings": { ... any settings ... },
    "mappings": {
        "type_one": { ... any mappings ... },
        "type_two": { ... any mappings ... },
        ...
    }
}
```

如果你想禁止自动创建索引，你 可以通过在 `config/elasticsearch.yml` 的每个节点下添加下面的配置：

```js
action.auto_create_index: false
```

## 删除一个索引

用以下的请求来 删除索引:

```js
DELETE /my_index
```



你也可以这样删除多个索引：

```js
DELETE /index_one,index_two
DELETE /index_*
```



你甚至可以这样删除 *全部* 索引：

```js
DELETE /_all
DELETE /*
```

如果你想要避免意外的大量删除, 你可以在你的 `elasticsearch.yml` 做如下配置：

```
action.destructive_requires_name: true
```

这个设置使删除只限于特定名称指向的数据, 而不允许通过指定 `_all` 或通配符来删除指定索引库。



## 索引设置

你可以通过修改配置来自定义索引行为，详细配置参照

下面是两个 最重要的设置：

- **`number_of_shards`**

  每个索引的主分片数，默认值是 `5` 。这个配置在索引创建后不能修改。

- **`number_of_replicas`**

  每个主分片的副本数，默认值是 `1` 。对于活动的索引库，这个配置可以随时修改。





例如，我们可以创建只有 一个主分片，没有副本的小索引：



```sense
PUT /my_temp_index
{
    "settings": {
        "number_of_shards" :   1,
        "number_of_replicas" : 0
    }
}
```

然后，我们可以用 `update-index-settings` API 动态修改副本数：

```sense
PUT /my_temp_index/_settings
{
    "number_of_replicas": 1
}
```

##  配置分析器

用来配置已存在的分析器或针对你的索引创建新的自定义分析器。

`standard` 分析器是用于全文字段的默认分析器，对于大部分西方语系来说是一个不错的选择。 它包括了以下几点：

- `standard` 分词器，通过单词边界分割输入的文本。
- `standard` 语汇单元过滤器，目的是整理分词器触发的语汇单元（但是目前什么都没做）。
- `lowercase` 语汇单元过滤器，转换所有的语汇单元为小写。
- `stop` 语汇单元过滤器，删除停用词—对搜索相关性影响不大的常用词，如 `a` ， `the` ， `and` ， `is` 。



默认情况下，停用词过滤器是被禁用的。如需启用它，你可以通过创建一个基于 `standard` 分析器的自定义分析器并设置 `stopwords` 参数。 可以给分析器提供一个停用词列表，或者告知使用一个基于特定语言的预定义停用词列表。

在下面的例子中，我们创建了一个新的分析器，叫做 `es_std` ， 并使用预定义的西班牙语停用词列表：

```sense
PUT /spanish_docs
{
    "settings": {
        "analysis": {
            "analyzer": {
                "es_std": {
                    "type":      "standard",
                    "stopwords": "_spanish_"
                }
            }
        }
    }
}
```



## 自定义分析器

一个 *分析器* 就是在一个包里面组合了三种函数的一个包装器， 三种函数按照顺序被执行

### **字符过滤器**

字符过滤器 用来 `整理` 一个尚未被分词的字符串。例如，如果我们的文本是HTML格式的，它会包含像 `<p>` 或者 `<div>` 这样的HTML标签，这些标签是我们不想索引的。我们可以使用 [`html清除` 字符过滤器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-htmlstrip-charfilter.html) 来移除掉所有的HTML标签，并且像把 `Á` 转换为相对应的Unicode字符 `Á` 这样，转换HTML实体。

一个分析器可能有0个或者多个字符过滤器。

### **分词器**

一个分析器 *必须* 有一个唯一的分词器。 分词器把字符串分解成单个词条或者词汇单元。 `标准` 分析器里使用的 [`标准` 分词器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-standard-tokenizer.html) 把一个字符串根据单词边界分解成单个词条，并且移除掉大部分的标点符号，然而还有其他不同行为的分词器存在。

例如， [`关键词` 分词器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-keyword-tokenizer.html) 完整地输出 接收到的同样的字符串，并不做任何分词。 [`空格` 分词器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-whitespace-tokenizer.html) 只根据空格分割文本 。 [`正则` 分词器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-pattern-tokenizer.html) 根据匹配正则表达式来分割文本 。



### **词单元过滤器**

经过分词，作为结果的 *词单元流* 会按照指定的顺序通过指定的词单元过滤器 。

词单元过滤器可以修改、添加或者移除词单元。我们已经提到过 [`lowercase` ](http://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lowercase-tokenizer.html)和 [`stop` 词过滤器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-stop-tokenfilter.html) ，但是在 Elasticsearch 里面还有很多可供选择的词单元过滤器。 [词干过滤器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-stemmer-tokenfilter.html) 把单词 `遏制` 为 词干。 [`ascii_folding` 过滤器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-asciifolding-tokenfilter.html)移除变音符，把一个像 `"très"` 这样的词转换为 `"tres"` 。 [`ngram`](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-ngram-tokenfilter.html) 和 [`edge_ngram` 词单元过滤器](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/analysis-edgengram-tokenfilter.html) 可以产生 适合用于部分匹配或者自动补全的词单元。



### 创建一个自定义分析器

**基本语法**

```js
PUT /my_index
{
    "settings": {
        "analysis": { 
            "char_filter": { ... custom character filters ... },
            "tokenizer":   { ...    custom tokenizers     ... },
            "filter":      { ...   custom token filters   ... },
            "analyzer":    { ...    custom analyzers      ... }
        }
    }
}
```

**自定义映射过滤器**

```
"char_filter": {
    "&_to_and": {
        "type":       "mapping",
        "mappings": [ "&=> and "]
    }
}
```

**自定义token filter**

```js
"filter": {
    "my_stopwords": {
        "type":        "stop",
        "stopwords": [ "the", "a" ]
    }
}
```

**创建分析器**

```js
"analyzer": {
    "my_analyzer": {
        "type":           "custom",
        "char_filter":  [ "html_strip", "&_to_and" ],
        "tokenizer":      "standard",
        "filter":       [ "lowercase", "my_stopwords" ]
    }
}
```

## 类型和映射

### **Lucene 如何处理文档**

* 在 Lucene 中，一个文档由一组简单的键值对组成。 每个字段都可以有多个值，但至少要有一个值
* **一个字符串可以通过分析过程转化为多个值**
* Lucene 不关心这些值是字符串、数字或日期—所有的值都被当做 *不透明字节* 。
* 当我们在 Lucene 中索引一个文档时，每个字段的值都被添加到相关字段的倒排索引中

你也可以将未处理的原始数据 *存储* 起来，以便这些原始数据在之后也可以被检索到。

### 类型是如何实现的

Elasticsearch 类型是以 Lucene 处理文档的这个方式为基础来实现的

一个索引可以有多个类型，这些类型的文档可以存储在相同的索引中。

Lucene 没有文档类型的概念，每个文档的类型名被存储在一个叫 `_type` 的元数据字段上。 当我们要检索某个类型的文档时, Elasticsearch 通过在 `_type` 字段上使用过滤器限制只返回这个类型的文档。

Lucene 也没有映射的概念。 **映射是 Elasticsearch 将复杂 JSON 文档 *映射* 成 Lucene 需要的扁平化数据的方式**。

### 根对象

映射的最高一层被称为 *根对象* ，它可能包含下面几项：

- 一个 *properties* 节点，列出了文档中可能包含的每个字段的映射
- 各种元数据字段，它们都以一个下划线开头，例如 `_type` 、 `_id` 和 `_source`
- 设置项，控制如何动态处理新的字段，例如 `analyzer` 、 `dynamic_date_formats` 和 `dynamic_templates`
- 其他设置，可以同时应用在根对象和其他 `object` 类型的字段上，例如 `enabled` 、 `dynamic` 和 `include_in_all`

#### 属性

- **`type`**

  字段的数据类型，例如 `string` 或 `date`

- **`index`**

  字段是否应当被当成全文来搜索（ `analyzed` ），或被当成一个准确的值（ `not_analyzed` ），还是完全不可被搜索（ `no` ）

- **`analyzer`**

  确定在索引和搜索时全文字段使用的 `analyzer`

我们将在本书的后续部分讨论其他字段类型，例如 `ip` 、 `geo_point` 和 `geo_shape` 。

#### 元数据: _source 字段

默认地，Elasticsearch 在 `_source` 字段存储代表文档体的JSON字符串，和所有被存储的字段一样， `_source` 字段在被写入磁盘之前先会被压缩。

这个字段的存储几乎总是我们想要的，因为它意味着下面的这些：

* 没必要从另一个存储库中拉取源数据
* *update* 请求需要该字段
* 可以部分取出某些字段
* 可以方便重建索引

**禁用元数据存储**

```js
PUT /my_index
{
    "mappings": {
        "my_type": {
            "_source": {
                "enabled":  false
            }
        }
    }
}
```

#### 元数据: _all 字段

`_all` 字段在新应用的探索阶段，当你还不清楚文档的最终结构时是比较有用的。你可以使用这个字段来做任何查询，并且有很大可能找到需要的文档：

**禁用**

```js
PUT /my_index/_mapping/my_type
{
    "my_type": {
        "_all": { "enabled": false }
    }
}
```

过 `include_in_all` 设置来逐个控制字段是否要包含在 `_all` 字段中，默认值是 `true`

在一个对象(或根对象)上设置 `include_in_all` 可以修改这个对象中的所有字段的默认行为。

记住，`_all` 字段仅仅是一个 经过分词的 `string` 字段。它使用默认分词器来分析它的值，不管这个值原本所在字段指定的分词器。就像所有 `string` 字段，你可以配置 `_all` 字段使用的分词器：



#### 元数据：文档标识

文档标识与四个元数据字段相关：

- **`_id`**

  文档的 ID 字符串

- **`_type`**

  文档的类型名

- **`_index`**

  文档所在的索引

- **`_uid`**

  `_type` 和 `_id` 连接在一起构造成 `type#id`

默认情况下， `_uid` 字段是被存储（可取回）和索引（可搜索）的。 `_type` 字段被索引但是没有存储， `_id` 和 `_index` 字段则既没有被索引也没有被存储，这意味着它们并不是真实存在的。

## 动态映射

当 Elasticsearch 遇到文档中以前 未遇到的字段，它用 [*dynamic mapping*](https://www.elastic.co/guide/cn/elasticsearch/guide/current/mapping-intro.html) 来确定字段的数据类型并自动把新的字段添加到类型映射。

有时这是想要的行为有时又不希望这样。通常没有人知道以后会有什么新字段加到文档，但是又希望这些字段被自动的索引。也许你只想忽略它们。如果Elasticsearch是作为重要的数据存储，可能就会期望遇到新字段就会抛出异常，这样能及时发现问题。

幸运的是可以用 `dynamic` 配置来控制这种行为 ，可接受的选项如下：

- **`true`**

  动态添加新的字段—缺省

- **`false`**

  忽略新的字段

- **`strict`**

  如果遇到新字段抛出异常

```sense
PUT /my_index
{
    "mappings": {
        "my_type": {
            "dynamic":      "strict", 
            "properties": {
                "title":  { "type": "string"},
                "stash":  {
                    "type":     "object",
                    "dynamic":  true 
                }
            }
        }
    }
}
```

* my_type不允许新增字段

* stash 可以新增字段

  

## 自定义动态映射

有时候，动态映射 `规则` 可能不太智能，我们可以通过设置去自定义这些规则

### 日期检测

日期检测可以通过在根对象上设置 `date_detection` 为 `false` 来关闭：

```js
PUT /my_index
{
    "mappings": {
        "my_type": {
            "date_detection": false
        }
    }
}
```

使用这个映射，字符串将始终作为 `string` 类型。如果你需要一个 `date` 字段，你必须手动添加。

Elasticsearch 判断字符串为日期的规则可以通过 [`dynamic_date_formats` setting](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/dynamic-field-mapping.html#date-detection) 来设置。

### 动态模板

使用 `dynamic_templates` ，你可以完全控制新检测生成字段的映射。你甚至可以通过**字段名称**或**数据类型**来应用不同的映射。



每个模板都有一个名称，你可以用来描述这个模板的用途， 一个 `mapping` 来指定映射应该怎样使用，以及至少一个参数 (如 `match`) 来定义这个模板适用于哪个字段。



模板按照顺序来检测；第一个匹配的模板会被启用。例如，我们给 `string` 类型字段定义两个模板：

```sense
PUT /my_index
{
    "mappings": {
        "my_type": {
            "dynamic_templates": [
                { "es": {
                      "match":              "*_es", 
                      "match_mapping_type": "string",
                      "mapping": {
                          "type":           "string",
                          "analyzer":       "spanish"
                      }
                }},
                { "en": {
                      "match":              "*", 
                      "match_mapping_type": "string",
                      "mapping": {
                          "type":           "string",
                          "analyzer":       "english"
                      }
                }}
            ]
}}}
```



##  缺省映射

通常，一个索引中的所有类型共享相同的字段和设置。 `_default_` 映射更加方便地指定通用设置，而不是每次创建新类型时都要重复设置。 `_default_` 映射是新类型的模板。在设置 `_default_` 映射之后创建的所有类型都将应用这些缺省的设置，除非类型在自己的映射中明确覆盖这些设置。



```sense
PUT /my_index
{
    "mappings": {
        "_default_": {
            "_all": { "enabled":  false }
        },
        "blog": {
            "_all": { "enabled":  true  }
        }
    }
}
```

## 重新索引数据

字段 `_source` 的一个优点是在Elasticsearch中已经有整个文档。你不必从源数据中重建索引，而且那样通常比较慢。

为了有效的重新索引所有在旧的索引中的文档，用 [*scroll*](https://www.elastic.co/guide/cn/elasticsearch/guide/current/scroll.html) 从旧的索引检索批量文档 ， 然后用 [`bulk` API](https://www.elastic.co/guide/cn/elasticsearch/guide/current/bulk.html) 把文档推送到新的索引中。

从Elasticsearch v2.3.0开始， [Reindex API](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-reindex.html) 被引入。它能够对文档重建索引而不需要任何插件或外部工具。

```js
GET /old_index/_search?scroll=1m
{
    "query": {
        "range": {
            "date": {
                "gte":  "2014-01-01",
                "lt":   "2014-02-01"
            }
        }
    },
    "sort": ["_doc"],
    "size":  1000
}
```

## 索引别名和零停机

重建索引的问题是必须更新应用中的索引名称。 索引别名就是用来解决这个问题的！

索引 *别名* 就像一个快捷方式或软连接，可以指向一个或多个索引，也可以给任何一个需要索引名的API来使用。*别名* 带给我们极大的灵活性，允许我们做下面这些：

* 无缝切换索引
* 索引分组
* 当做视图使用



有两种方式管理别名： `_alias` 用于单个操作， `_aliases` 用于执行多个原子级操作。



```sense
# 创建索引
PUT /my_index_v1 
# 创建别名
PUT /my_index_v1/_alias/my_index 
# 这个别名指向哪一个索引：
GET /*/_alias/my_index
# 哪些别名指向这个索引：
GET /my_index_v1/_alias/*

# 重新索引
# 然后我们将数据从 my_index_v1 索引到 my_index_v2 
PUT /my_index_v2
{
    "mappings": {
        "my_type": {
            "properties": {
                "tags": {
                    "type":   "string",
                    "index":  "not_analyzed"
                }
            }
        }
    }
}
```

一个别名可以指向多个索引，所以我们在添加别名到新索引的同时必须从旧的索引中删除它。这个操作需要原子化，这意味着我们需要使用 `_aliases` 操作：

```sense
POST /_aliases
{
    "actions": [
        { "remove": { "index": "my_index_v1", "alias": "my_index" }},
        { "add":    { "index": "my_index_v2", "alias": "my_index" }}
    ]
}
```

